from langchain.chat_models import AzureChatOpenAI
from langchain.chains.summarize import load_summarize_chain
from langchain.prompts import PromptTemplate
from langchain.docstore.document import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Step 1: Initialize your Azure OpenAI model
llm = AzureChatOpenAI(
    deployment_name="your-deployment-name",
    openai_api_version="2023-05-15",
    openai_api_key="your-api-key",
    openai_api_base="https://your-resource-name.openai.azure.com/",
    model_name="gpt-35-turbo",
    temperature=0
)

# Step 2: Split the existing text_content string
splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=300)
chunks = splitter.split_text(text_content)
docs = [Document(page_content=chunk) for chunk in chunks]

# Step 3: Define custom prompts
initial_prompt_template = PromptTemplate(
    input_variables=["text"],
    template="""
You are an expert meeting assistant. Summarize the following MS Teams meeting transcript:
{text}

Provide a structured summary including:
- Meeting Title
- Date & Time
- Participants
- Key Points Discussed
- Action Items
- Decisions Made
- Any Issues Raised
"""
)

refine_prompt_template = PromptTemplate(
    input_variables=["existing_answer", "text"],
    template="""
You are refining an existing meeting summary with additional transcript context.

Current summary:
{existing_answer}

Additional transcript:
{text}

Update and expand the summary if needed. Maintain the same structured format.
"""
)

# Step 4: Run refine chain
refine_chain = load_summarize_chain(
    llm,
    chain_type="refine",
    question_prompt=initial_prompt_template,
    refine_prompt=refine_prompt_template,
    return_intermediate_steps=False
)

# Step 5: Get final summary
summary = refine_chain.run(docs)
print(summary)
