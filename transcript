from langchain.prompts import PromptTemplate
from langchain.chains.summarize import load_summarize_chain
from langchain.chat_models import ChatOpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Your extracted transcript content
text_content = """Your large transcript text goes here..."""

# 1. Split the transcript into chunks
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=100
)
docs = text_splitter.create_documents([text_content])

# 2. Prompt templates for Refine chain
initial_prompt = PromptTemplate(
    input_variables=["text"],
    template="""
You are an AI assistant that summarizes meeting transcripts.

Summarize the following transcript portion:

{text}
"""
)

refine_prompt = PromptTemplate(
    input_variables=["existing_answer", "text"],
    template="""
We have an existing summary:
{existing_answer}

Refine the summary with this new transcript portion:
{text}

Return an updated summary.
"""
)

# 3. Load the refine chain
llm = ChatOpenAI(temperature=0, model="gpt-3.5-turbo")
refine_chain = load_summarize_chain(
    llm,
    chain_type="refine",
    question_prompt=initial_prompt,
    refine_prompt=refine_prompt,
    return_intermediate_steps=False
)

# 4. Run the chain using .invoke() (not deprecated)
summary = refine_chain.invoke({"input_documents": docs})

# 5. Output the final summary
print(summary['output_text'])
